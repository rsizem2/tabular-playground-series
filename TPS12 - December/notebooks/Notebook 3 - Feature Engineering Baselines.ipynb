{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a755fecf",
   "metadata": {},
   "source": [
    "# TPS12 - Feature Engineering Baselines\n",
    "\n",
    "In this notebook we take our feature engineering techniques from the previous notebooks and test them all together and compare with a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ac29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 3\n",
    "TRAIN_SIZE = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da66ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pyarrow\n",
    "import gc\n",
    "\n",
    "# Model/Evaluation\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59053c98",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61213985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full training data\n",
    "train = pd.read_feather('../data/train.feather')\n",
    "\n",
    "# Drop low/no variance \n",
    "train.drop([\"Soil_Type7\", \"Id\", \"Soil_Type15\"], axis=1, inplace=True)\n",
    "train = train[train.Cover_Type != 5]\n",
    "\n",
    "# Label Encoding\n",
    "new_encoder = LabelEncoder()\n",
    "train[\"Cover_Type\"] = new_encoder.fit_transform(train[\"Cover_Type\"])\n",
    "\n",
    "# Split synthetic data\n",
    "train, test = train_test_split(\n",
    "    train, \n",
    "    train_size = TRAIN_SIZE, \n",
    "    random_state = RANDOM_SEED,\n",
    "    stratify = train['Cover_Type'],\n",
    ")\n",
    "y_train = train['Cover_Type']\n",
    "\n",
    "\n",
    "# features, data structure for summary scores\n",
    "features = [x for x in train.columns if x not in ['Id','Cover_Type']]\n",
    "nonsoil = [x for x in features if not x.startswith('Soil_Type')]\n",
    "new_rows = list()\n",
    "gc.collect()\n",
    "\n",
    "print(f'Training Size: {train.shape[0]} rows, {train.shape[1]} cols')\n",
    "print(f'Holdout Size: {test.shape[0]} rows, {test.shape[1]} cols\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1ba09",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c50d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a543a5",
   "metadata": {},
   "source": [
    "# Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14251f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_features(sklearn_model, processing = None):\n",
    "    \n",
    "    # Original Training/Test Split\n",
    "    features = [x for x in train.columns if x not in ['Id','Cover_Type']]\n",
    "    X_temp, X_test = train[features], test[features]\n",
    "    y_temp, y_test = train['Cover_Type'], test['Cover_Type']\n",
    "    \n",
    "    # Feature Engineering\n",
    "    if processing:\n",
    "        X_temp = processing(X_temp)\n",
    "        X_test = processing(X_test)\n",
    "    features = [x for x in X_temp.columns]\n",
    "    \n",
    "    # Store the out-of-fold predictions\n",
    "    test_preds = np.zeros((X_test.shape[0],6))\n",
    "    oof_preds = np.zeros((X_temp.shape[0],))\n",
    "    fi_scores = np.zeros((X_temp.shape[1],))\n",
    "    scores, times = np.zeros(NUM_FOLDS), np.zeros(NUM_FOLDS)\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X_temp,y_temp)):\n",
    "       \n",
    "        # Training and Validation Sets\n",
    "        X_train, X_valid = X_temp.iloc[train_idx], X_temp.iloc[valid_idx]\n",
    "        y_train, y_valid = y_temp.iloc[train_idx], y_temp.iloc[valid_idx]\n",
    "        \n",
    "        # Create model\n",
    "        start = time.time()\n",
    "        model = clone(sklearn_model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Permutation Importance\n",
    "        result = permutation_importance(\n",
    "            model, X_valid, y_valid, \n",
    "            n_repeats=10, random_state=RANDOM_SEED\n",
    "        )\n",
    "        fi_scores += result.importances_mean / NUM_FOLDS\n",
    "\n",
    "        # validation/holdout predictions\n",
    "        valid_preds = np.ravel(model.predict(X_valid))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        test_preds += model.predict_proba(X_test)\n",
    "\n",
    "        # Save scores and times\n",
    "        scores[fold] = accuracy_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        times[fold] = end-start\n",
    "        print(f'Fold {fold} Accuracy:  {round(scores[fold], 5)} in {round(end-start,2)}s.')\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    nonsoil = [x for x in X_test.columns if not x.startswith('Soil_Type')]\n",
    "    test_preds = np.argmax(test_preds, axis = 1)\n",
    "    test_score = accuracy_score(y_test, test_preds)\n",
    "    #print('\\n'+model.__class__.__name__)\n",
    "    print(\"Train Accuracy:\", round(scores.mean(), 5))\n",
    "    print('Test Accuracy:', round(test_score, 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    fi_scores = pd.Series(\n",
    "        data = fi_scores, \n",
    "        index = features\n",
    "    ).loc[nonsoil].sort_values()\n",
    "    \n",
    "    return scores.mean(), oof_preds, test_score, fi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc67b02",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654cf0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e0f138",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0f34fb2",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad2a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
