{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfac5570",
   "metadata": {},
   "source": [
    "# Tweaking Class Probabilities\n",
    "\n",
    "In this final notebook, we attempt to fix a shortcoming of the ExtraTrees based models by manually tweaking the class probabilities predicted by our models. Our goal is to make our predicted label distribution more similar to the training label distribution. This is based of this [kaggle notebook](https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28027de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 10\n",
    "EXT_PARAMS = dict(n_estimators = 300, random_state = RANDOM_SEED, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f951254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Generic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Optimized scikit-learn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Other stuff\n",
    "from math import factorial\n",
    "from random import choices, setstate\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8fb789",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eb886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense/\n",
    "from math import factorial\n",
    "from random import choices, setstate\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "def bias(w, x, y, z):\n",
    "    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n",
    "\n",
    "def bias_of(column):\n",
    "    w = int(column[1:column.index('T')])\n",
    "    x = int(column[column.index('T')+1:column.index('G')])\n",
    "    y = int(column[column.index('G')+1:column.index('C')])\n",
    "    z = int(column[column.index('C')+1:])\n",
    "    return bias(w, x, y, z)\n",
    "\n",
    "def get_histograms(input_df):\n",
    "    return pd.DataFrame({\n",
    "        col: ((input_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in features\n",
    "    })\n",
    "\n",
    "def gcd_of_all(df_i):\n",
    "    gcd = df_i[features[0]]\n",
    "    for col in features[1:]:\n",
    "        gcd = np.gcd(gcd, df_i[col])\n",
    "    return gcd\n",
    "\n",
    "def get_target_bins():\n",
    "    temp = train[['target','target']].copy()\n",
    "    temp.columns = ['row_id','target']\n",
    "    temp['row_id'] = gcd_of_all(get_histograms(train[features]))\n",
    "    return temp['row_id'].astype(str) + temp['target'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90becef7",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d2c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring/Training Baseline Function\n",
    "def score_model(sklearn_model):\n",
    "    \n",
    "    # Store the holdout predictions\n",
    "    oof_preds = np.zeros((len(train),))\n",
    "    test_proba = np.zeros((len(test),len(train['target'].unique())))\n",
    "    test_preds = list()\n",
    "    scores = np.zeros(NUM_FOLDS)\n",
    "    print('')\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    for fold, (train_idx, valid_idx) in enumerate(SKF.split(train, target_bins)):\n",
    "        \n",
    "        # Train/Test/Validation Sets\n",
    "        X_train, y_train = train[features + ['gcd']].iloc[train_idx], train['target'].iloc[train_idx]\n",
    "        X_valid, y_valid = train[features + ['gcd']].iloc[valid_idx], train['target'].iloc[valid_idx]\n",
    "        train_weights, valid_weights = train['sample_weight'].iloc[train_idx], train['sample_weight'].iloc[valid_idx]\n",
    "        X_test = test[features + ['gcd']]; start = time.time()\n",
    "        \n",
    "        # Train Model\n",
    "        model = clone(sklearn_model)\n",
    "        model.fit(X_train, y_train, sample_weight = train_weights)\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get Predictions\n",
    "        valid_preds = np.argmax(model.predict_proba(X_valid), axis = 1)\n",
    "        test_prob = model.predict_proba(X_test)\n",
    "        \n",
    "        # Save Predictions\n",
    "        test_proba += test_prob / NUM_FOLDS\n",
    "        test_preds.append(np.argmax(test_prob, axis = 1))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "    \n",
    "    print(\"\\nAverage Accuracy:\", round(accuracy_score(train['target'], oof_preds, sample_weight = train['sample_weight']), 5))\n",
    "    # return oof_preds, np.argmax(test_proba, axis = 1), mode(test_preds).mode[0]\n",
    "    return oof_preds, test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2c0ea",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b47937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 123993\n",
      "CPU times: total: 1.67 s\n",
      "Wall time: 421 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Bacteroides_fragilis\n",
       "1        Campylobacter_jejuni\n",
       "2          Enterococcus_hirae\n",
       "3            Escherichia_coli\n",
       "4      Escherichia_fergusonii\n",
       "5       Klebsiella_pneumoniae\n",
       "6         Salmonella_enterica\n",
       "7       Staphylococcus_aureus\n",
       "8    Streptococcus_pneumoniae\n",
       "9      Streptococcus_pyogenes\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_feather('../data/train.feather')\n",
    "features = [x for x in train.columns if x not in ['row_id','target','sample_weight','gcd']]\n",
    "\n",
    "# Stratified K-fold\n",
    "SKF = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "\n",
    "# Training label distribution\n",
    "label_dist = train['target'].value_counts().sort_index() / len(train) * 100\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train['target'] = encoder.fit_transform(train['target'])\n",
    "target_bins = train['target'].astype(str) + train['gcd'].astype(str)\n",
    "test = pd.read_feather('../data/test.feather')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(f'Training Samples: {len(train)}')\n",
    "pd.Series(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60840d3",
   "metadata": {},
   "source": [
    "# Original Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812ae1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.098957\n",
       "Campylobacter_jejuni        10.056213\n",
       "Enterococcus_hirae           9.978789\n",
       "Escherichia_coli             9.917495\n",
       "Escherichia_fergusonii       9.907817\n",
       "Klebsiella_pneumoniae       10.016694\n",
       "Salmonella_enterica          9.992500\n",
       "Staphylococcus_aureus       10.012662\n",
       "Streptococcus_pneumoniae    10.013469\n",
       "Streptococcus_pyogenes      10.005404\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b59f29",
   "metadata": {},
   "source": [
    "# ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd73178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Accuracy: 0.9563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.035\n",
       "Campylobacter_jejuni        10.236\n",
       "Enterococcus_hirae           9.676\n",
       "Escherichia_coli             8.369\n",
       "Escherichia_fergusonii      11.077\n",
       "Klebsiella_pneumoniae       10.181\n",
       "Salmonella_enterica         10.284\n",
       "Staphylococcus_aureus        9.951\n",
       "Streptococcus_pneumoniae    10.078\n",
       "Streptococcus_pyogenes      10.113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTrees Baseline\n",
    "oof_preds, test_proba = score_model(\n",
    "    ExtraTreesClassifier(**EXT_PARAMS)\n",
    ")\n",
    "\n",
    "y_preds = encoder.inverse_transform(np.argmax(test_proba, axis=1))\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b718e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.007\n",
       "Campylobacter_jejuni        10.227\n",
       "Enterococcus_hirae           9.762\n",
       "Escherichia_coli             9.793\n",
       "Escherichia_fergusonii      10.034\n",
       "Klebsiella_pneumoniae       10.094\n",
       "Salmonella_enterica         10.029\n",
       "Staphylococcus_aureus        9.924\n",
       "Streptococcus_pneumoniae    10.060\n",
       "Streptococcus_pyogenes      10.070\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_proba = test_proba + np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\n",
    "y_preds = encoder.inverse_transform(np.argmax(new_proba, axis=1))\n",
    "\n",
    "submission['target'] = y_preds\n",
    "submission.to_csv('../submissions/extratrees_tweaked.csv', index=False)\n",
    "\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a446b3",
   "metadata": {},
   "source": [
    "# ExtraTrees w/ Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3867ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Accuracy: 0.95896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.033\n",
       "Campylobacter_jejuni        10.228\n",
       "Enterococcus_hirae           9.680\n",
       "Escherichia_coli             8.508\n",
       "Escherichia_fergusonii      10.936\n",
       "Klebsiella_pneumoniae       10.258\n",
       "Salmonella_enterica         10.208\n",
       "Staphylococcus_aureus        9.982\n",
       "Streptococcus_pneumoniae    10.063\n",
       "Streptococcus_pyogenes      10.104\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTrees Baseline\n",
    "oof_preds, test_proba1 = score_model(\n",
    "    BaggingClassifier(ExtraTreesClassifier(**EXT_PARAMS), random_state = RANDOM_SEED)\n",
    ")\n",
    "\n",
    "y_preds = encoder.inverse_transform(np.argmax(test_proba1, axis=1))\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15afb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.016\n",
       "Campylobacter_jejuni        10.213\n",
       "Enterococcus_hirae           9.797\n",
       "Escherichia_coli             9.651\n",
       "Escherichia_fergusonii      10.096\n",
       "Klebsiella_pneumoniae       10.146\n",
       "Salmonella_enterica         10.036\n",
       "Staphylococcus_aureus        9.941\n",
       "Streptococcus_pneumoniae    10.044\n",
       "Streptococcus_pyogenes      10.060\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_proba1 = test_proba1 + np.array([0, 0, 0.01, 0.022, 0, 0, 0, 0, 0, 0])\n",
    "y_preds = encoder.inverse_transform(np.argmax(new_proba1, axis=1))\n",
    "\n",
    "submission['target'] = y_preds\n",
    "submission.to_csv('../submissions/bagging_tweaked.csv', index=False)\n",
    "\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf67f3d",
   "metadata": {},
   "source": [
    "# Separate High/Low Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d6b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourResolutions(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, base_estimator = ExtraTreesClassifier(**EXT_PARAMS)):\n",
    "        self.base_estimator = base_estimator\n",
    "        \n",
    "    def clone_models(self):\n",
    "        self.model1 = clone(self.base_estimator) # Model for 1,000,000 BOC Reads\n",
    "        self.model2 = clone(self.base_estimator) # Model for 100,000 BOC Reads\n",
    "        self.model3 = clone(self.base_estimator) # Model for 1,000 BOC Reads\n",
    "        self.model4 = clone(self.base_estimator) # Model for 100 BOC Reads\n",
    "            \n",
    "    def gcd_of_all(self, df_i):\n",
    "        features = [x for x in df_i.columns]\n",
    "        gcd = df_i[features[0]]\n",
    "        for col in features[1:]:\n",
    "            gcd = np.gcd(gcd, df_i[col])\n",
    "        self.gcd1 = (gcd == 1)\n",
    "        self.gcd2 = (gcd == 10)\n",
    "        self.gcd3 = (gcd == 1000)\n",
    "        self.gcd4 = (gcd == 10000)\n",
    "        \n",
    "    def get_histograms(self, input_df):\n",
    "        return pd.DataFrame({\n",
    "            col: ((input_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in features\n",
    "        })\n",
    "        \n",
    "    def fit(self, X, y, sample_weight = None):\n",
    "        self.clone_models()\n",
    "        temp = self.get_histograms(X)\n",
    "        self.gcd_of_all(temp)\n",
    "        self.num_labels = len(np.unique(y))\n",
    "        if sample_weight is not None:\n",
    "            self.model1.fit(X[self.gcd1], y[self.gcd1], sample_weight[self.gcd1])\n",
    "            self.model2.fit(X[self.gcd2], y[self.gcd2], sample_weight[self.gcd2])\n",
    "            self.model3.fit(X[self.gcd3], y[self.gcd3], sample_weight[self.gcd3])\n",
    "            self.model4.fit(X[self.gcd4], y[self.gcd4], sample_weight[self.gcd4])\n",
    "        else:\n",
    "            self.model1.fit(X[self.gcd1], y[self.gcd1])\n",
    "            self.model2.fit(X[self.gcd2], y[self.gcd2])\n",
    "            self.model3.fit(X[self.gcd3], y[self.gcd3])\n",
    "            self.model4.fit(X[self.gcd4], y[self.gcd4])\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        temp = self.get_histograms(X)\n",
    "        self.gcd_of_all(temp)\n",
    "        temp = np.zeros((len(X),self.num_labels))\n",
    "        temp[self.gcd1] = self.model1.predict_proba(X[self.gcd1])\n",
    "        temp[self.gcd2] = self.model2.predict_proba(X[self.gcd2])\n",
    "        temp[self.gcd3] = self.model3.predict_proba(X[self.gcd3])\n",
    "        temp[self.gcd4] = self.model4.predict_proba(X[self.gcd4])\n",
    "        return temp\n",
    "        \n",
    "    def predict(self, X):\n",
    "        temp = self.get_histograms(X)\n",
    "        self.gcd_of_all(temp)\n",
    "        temp = np.zeros((len(X),))\n",
    "        temp[self.gcd1] = self.model1.predict(X[self.gcd1])\n",
    "        temp[self.gcd2] = self.model2.predict(X[self.gcd2])\n",
    "        temp[self.gcd3] = self.model3.predict(X[self.gcd3])\n",
    "        temp[self.gcd4] = self.model4.predict(X[self.gcd4])\n",
    "        return temp.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835c2565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Accuracy: 0.95578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.052\n",
       "Campylobacter_jejuni        10.238\n",
       "Enterococcus_hirae           9.664\n",
       "Escherichia_coli             8.507\n",
       "Escherichia_fergusonii      10.929\n",
       "Klebsiella_pneumoniae       10.214\n",
       "Salmonella_enterica         10.257\n",
       "Staphylococcus_aureus        9.949\n",
       "Streptococcus_pneumoniae    10.091\n",
       "Streptococcus_pyogenes      10.099\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTrees Baseline\n",
    "oof_preds, test_proba2 = score_model(\n",
    "    FourResolutions()\n",
    ")\n",
    "\n",
    "y_preds = encoder.inverse_transform(np.argmax(test_proba2, axis=1))\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f3a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        10.014\n",
       "Campylobacter_jejuni        10.204\n",
       "Enterococcus_hirae           9.814\n",
       "Escherichia_coli             9.874\n",
       "Escherichia_fergusonii       9.993\n",
       "Klebsiella_pneumoniae       10.092\n",
       "Salmonella_enterica         10.001\n",
       "Staphylococcus_aureus        9.921\n",
       "Streptococcus_pneumoniae    10.046\n",
       "Streptococcus_pyogenes      10.041\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_proba2 = test_proba2 + np.array([0, 0, 0.015, 0.035, 0, 0, 0, 0, 0, 0])\n",
    "y_preds = encoder.inverse_transform(np.argmax(new_proba2, axis=1))\n",
    "\n",
    "submission['target'] = y_preds\n",
    "submission.to_csv('../submissions/four_models_tweaked.csv', index=False)\n",
    "\n",
    "pd.Series(y_preds, index=test.index).value_counts().sort_index() / len(test) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
