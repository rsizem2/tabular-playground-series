{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9c07c0",
   "metadata": {},
   "source": [
    "# Neural Network Baseline\n",
    "\n",
    "In this notebook, we get a baseline for a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39be25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b684c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import os\n",
    "import pyarrow\n",
    "import gc\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# Logging/Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tensorflow/Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# TF addons\n",
    "from tensorflow_addons.optimizers import SWA, Lookahead, AdamW\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set Seed\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a017fba",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748c52fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 824 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load data\n",
    "train = pd.read_feather(f'../data/train.feather')\n",
    "test = pd.read_feather('../data/test.feather')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# Get feature columns\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c7e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_skew = train[features].loc[:,train[features].skew() >= 2].columns  # with Skewed \n",
    "l_skew = train[features].loc[:,train[features].skew() < 2].columns   # Bimodal\n",
    "\n",
    "# Skewed distrubutions\n",
    "train['median_h'] = train[h_skew].median(axis=1)\n",
    "test['median_h'] = test[h_skew].median(axis=1)\n",
    "\n",
    "train['var_h'] = train[h_skew].var(axis=1)\n",
    "test['var_h'] = test[h_skew].var(axis=1)\n",
    "\n",
    "# Bimodal distributions\n",
    "train['mean_l'] = train[l_skew].mean(axis=1)\n",
    "test['mean_l'] = test[l_skew].mean(axis=1)\n",
    "\n",
    "train['std_l'] = train[l_skew].std(axis=1)\n",
    "test['std_l'] = test[l_skew].std(axis=1)\n",
    "\n",
    "train['median_l'] = train[l_skew].median(axis=1)\n",
    "test['median_l'] = test[l_skew].median(axis=1)\n",
    "\n",
    "train['skew_l'] = train[l_skew].skew(axis=1)\n",
    "test['skew_l'] = test[l_skew].skew(axis=1)\n",
    "\n",
    "train['max_l'] = train[l_skew].max(axis=1)\n",
    "test['max_l'] = test[l_skew].max(axis=1)\n",
    "\n",
    "train['var_l'] = train[l_skew].var(axis=1)\n",
    "test['var_l'] = test[l_skew].var(axis=1)\n",
    "\n",
    "# Update feature columns\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc710ec",
   "metadata": {},
   "source": [
    "# Scoring Function\n",
    "\n",
    "A benchmarking function which accepts two arguments:\n",
    "\n",
    "* model_builder - a function which creates a keras model\n",
    "* fit_params - parameters for the .fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c2243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring/Training Baseline Function\n",
    "def train_model(sklearn_model):\n",
    "    \n",
    "    # Store the holdout predictions\n",
    "    oof_preds = np.zeros((train.shape[0],))\n",
    "    test_preds = np.zeros((test.shape[0],))\n",
    "    scores = np.zeros(NUM_FOLDS)\n",
    "    times = np.zeros(NUM_FOLDS)\n",
    "    print('')\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['target'])):\n",
    "        \n",
    "        scaler = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MinMaxScaler()\n",
    "        )\n",
    "        \n",
    "        # Training and Validation Sets\n",
    "        X_train = scaler.fit_transform(train[features].iloc[train_idx])\n",
    "        X_valid = scaler.transform(train[features].iloc[valid_idx])\n",
    "        X_test = scaler.transform(test[features])\n",
    "        \n",
    "        # Training and Target Labels\n",
    "        y_train = train['target'].iloc[train_idx].to_numpy()\n",
    "        y_valid = train['target'].iloc[valid_idx].to_numpy()\n",
    "        \n",
    "        \n",
    "        # Create model\n",
    "        model = clone(sklearn_model)\n",
    "            \n",
    "        start = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # validation and test predictions\n",
    "        valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / NUM_FOLDS\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        \n",
    "        # fold auc score\n",
    "        fold_auc = roc_auc_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        print(f'Fold {fold} (AUC): {round(fold_auc, 5)} in {round(end-start,2)}s.')\n",
    "        scores[fold] = fold_auc\n",
    "        times[fold] = end-start\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    print(\"\\nAverage AUC:\", round(scores.mean(), 5))\n",
    "    print(\"Worst AUC:\", round(scores.min(), 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return scores, test_preds, oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca2e19",
   "metadata": {},
   "source": [
    "# MLP w/ Learning Rate Decay\n",
    "\n",
    "We follow the NN architecture from this [kaggle notebook](https://www.kaggle.com/adityasharma01/simple-nn-tps-nov-21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a55d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Parameters\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 1000\n",
    "INIT_LR = 2.65e-4\n",
    "EARLY_STOP = 20\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228ba7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.InputLayer(input_shape = (len(features),)),\n",
    "            layers.Dense(108, activation=\"swish\"),\n",
    "            layers.Dense(64, activation=\"swish\"),\n",
    "            layers.Dense(32, activation=\"swish\"),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate = INIT_LR,\n",
    "        ),\n",
    "        metrics=[tf.keras.metrics.AUC()],\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8946337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit parameters for Keras model\n",
    "baseline_model = KerasClassifier(\n",
    "    build_model,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = VERBOSE,\n",
    "    shuffle = True,\n",
    "    validation_split = 0.1,\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            patience=EARLY_STOP,\n",
    "            monitor='val_loss',\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.2, \n",
    "            patience=7, \n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac468aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.75379 in 210.52s.\n",
      "Fold 1 (AUC): 0.74887 in 223.53s.\n",
      "Fold 2 (AUC): 0.75186 in 281.04s.\n",
      "Fold 3 (AUC): 0.75429 in 225.41s.\n",
      "Fold 4 (AUC): 0.75135 in 208.11s.\n",
      "Fold 5 (AUC): 0.75156 in 236.88s.\n",
      "Fold 6 (AUC): 0.75555 in 236.65s.\n",
      "Fold 7 (AUC): 0.75147 in 267.44s.\n",
      "Fold 8 (AUC): 0.75353 in 200.61s.\n",
      "Fold 9 (AUC): 0.74782 in 241.68s.\n",
      "\n",
      "Average AUC: 0.75201\n",
      "Worst AUC: 0.74782\n",
      "Training Time: 2331.87s\n"
     ]
    }
   ],
   "source": [
    "# Simple NN Baseline\n",
    "scores, test_preds, oof_preds = train_model(baseline_model)\n",
    "\n",
    "submission['target'] = test_preds\n",
    "submission.to_csv('../output/simple_nn_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
