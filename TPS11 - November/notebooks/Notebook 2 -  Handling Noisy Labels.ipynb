{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf840a64",
   "metadata": {},
   "source": [
    "# TPS 11/21 - Handling Mislabeled Data\n",
    "\n",
    "In this notebook, we will explore the [cleanlab](https://github.com/cleanlab/cleanlab) library which provides functions for \"finding, quantifying, and learning with label errors in datasets.\" In particular, we will ese the `LearningWithNoisyLabels` wrapper with various scikit-learn cumpatible models to make predictions despite the mislabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23355eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb8103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import os\n",
    "import pyarrow\n",
    "import gc\n",
    "\n",
    "# cleanlab\n",
    "import cleanlab\n",
    "from cleanlab.classification import LearningWithNoisyLabels\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Models\n",
    "from sklearn.utils.extmath import softmax\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "# Optuna \n",
    "import optuna\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586e475",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8f59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 477 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load data\n",
    "train = pd.read_feather(f'../data/train.feather')\n",
    "test = pd.read_feather('../data/test.feather')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# Get feature columns\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a89196",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "We follow the feature engineering from this [kaggle notebook](https://www.kaggle.com/javiervallejos/simple-nn-with-good-results-tps-nov-21) by computing some row statistics on the skewed and bimodal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdea6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_skew = train[features].loc[:,train[features].skew() >= 2].columns  # with Skewed \n",
    "l_skew = train[features].loc[:,train[features].skew() < 2].columns   # Bimodal\n",
    "\n",
    "# Skewed distrubutions\n",
    "train['median_h'] = train[h_skew].median(axis=1)\n",
    "test['median_h'] = test[h_skew].median(axis=1)\n",
    "\n",
    "train['var_h'] = train[h_skew].var(axis=1)\n",
    "test['var_h'] = test[h_skew].var(axis=1)\n",
    "\n",
    "# Bimodal distributions\n",
    "train['mean_l'] = train[l_skew].mean(axis=1)\n",
    "test['mean_l'] = test[l_skew].mean(axis=1)\n",
    "\n",
    "train['std_l'] = train[l_skew].std(axis=1)\n",
    "test['std_l'] = test[l_skew].std(axis=1)\n",
    "\n",
    "train['median_l'] = train[l_skew].median(axis=1)\n",
    "test['median_l'] = test[l_skew].median(axis=1)\n",
    "\n",
    "train['skew_l'] = train[l_skew].skew(axis=1)\n",
    "test['skew_l'] = test[l_skew].skew(axis=1)\n",
    "\n",
    "train['max_l'] = train[l_skew].max(axis=1)\n",
    "test['max_l'] = test[l_skew].max(axis=1)\n",
    "\n",
    "train['var_l'] = train[l_skew].var(axis=1)\n",
    "test['var_l'] = test[l_skew].var(axis=1)\n",
    "\n",
    "# Update feature columns\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fc5af",
   "metadata": {},
   "source": [
    "# Scoring Function\n",
    "\n",
    "The following functions accept a scikit-learn compatible model or pipeline with fit, predict and predict_proba methods and return auc scores, out-of-fold predictions and test set predictions (averaged over each fold) for the vanilla models and the wrapped models, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acf56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring/Training Baseline Function\n",
    "def train_model(sklearn_model):\n",
    "    \n",
    "    # Store the holdout predictions\n",
    "    oof_preds = np.zeros((train.shape[0],))\n",
    "    test_preds = np.zeros((test.shape[0],))\n",
    "    scores = np.zeros(NUM_FOLDS)\n",
    "    times = np.zeros(NUM_FOLDS)\n",
    "    print('')\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['target'])):\n",
    "        \n",
    "        # Training and Validation Sets\n",
    "        X_train, y_train = train[features].iloc[train_idx].to_numpy(), train['target'].iloc[train_idx].to_numpy()\n",
    "        X_valid, y_valid = train[features].iloc[valid_idx].to_numpy(), train['target'].iloc[valid_idx].to_numpy()\n",
    "        X_test = test[features]\n",
    "        \n",
    "        # Create model\n",
    "        model = clone(sklearn_model)\n",
    "            \n",
    "        start = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # validation and test predictions\n",
    "        valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / NUM_FOLDS\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        \n",
    "        # fold auc score\n",
    "        fold_auc = roc_auc_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        print(f'Fold {fold} (AUC): {round(fold_auc, 5)} in {round(end-start,2)}s.')\n",
    "        scores[fold] = fold_auc\n",
    "        times[fold] = end-start\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    print(\"\\nAverage AUC:\", round(scores.mean(), 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return scores, test_preds, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1209d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring/Training function for LearningWithNoisyLabels\n",
    "def train_noisy_model(sklearn_model):\n",
    "    \n",
    "    # Store the holdout predictions\n",
    "    oof_preds = np.zeros((train.shape[0],))\n",
    "    test_preds = np.zeros((test.shape[0],))\n",
    "    scores = np.zeros(NUM_FOLDS)\n",
    "    times = np.zeros(NUM_FOLDS)\n",
    "    print('')\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['target'])):\n",
    "        \n",
    "        # Training and Validation Sets\n",
    "        X_train, y_train = train[features].iloc[train_idx].to_numpy(), train['target'].iloc[train_idx].to_numpy()\n",
    "        X_valid, y_valid = train[features].iloc[valid_idx].to_numpy(), train['target'].iloc[valid_idx].to_numpy()\n",
    "        X_test = test[features]\n",
    "        \n",
    "        # Create model\n",
    "        model = LearningWithNoisyLabels(\n",
    "            clf = clone(sklearn_model)\n",
    "        )\n",
    "            \n",
    "        start = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # validation and test predictions\n",
    "        valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / NUM_FOLDS\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        \n",
    "        # fold auc score\n",
    "        fold_auc = roc_auc_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        print(f'Fold {fold} (AUC): {round(fold_auc, 5)} in {round(end-start,2)}s.')\n",
    "        scores[fold] = fold_auc\n",
    "        times[fold] = end-start\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    print(\"\\nAverage AUC:\", round(scores.mean(), 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return scores, test_preds, oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f8e62",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a8f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logit_pipeline = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    LogisticRegression(\n",
    "        solver = 'saga',\n",
    "        max_iter = 200,\n",
    "        n_jobs = -1,\n",
    "        random_state = RANDOM_SEED,\n",
    "        C = 0.00093730740668689\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722452ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74915 in 119.43s.\n",
      "Fold 1 (AUC): 0.74864 in 120.18s.\n",
      "Fold 2 (AUC): 0.74984 in 119.35s.\n",
      "Fold 3 (AUC): 0.74989 in 128.84s.\n",
      "Fold 4 (AUC): 0.74917 in 117.17s.\n",
      "Fold 5 (AUC): 0.74772 in 116.77s.\n",
      "\n",
      "Average AUC: 0.74907\n",
      "Training Time: 721.75s\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Baseline\n",
    "logit_scores, logit_preds, logit_oof = train_model(logit_pipeline)\n",
    "\n",
    "submission['target'] = logit_preds\n",
    "submission.to_csv('../output/logit_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ae98e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74924 in 552.16s.\n",
      "Fold 1 (AUC): 0.74877 in 551.88s.\n",
      "Fold 2 (AUC): 0.74985 in 545.86s.\n",
      "Fold 3 (AUC): 0.7498 in 549.98s.\n",
      "Fold 4 (AUC): 0.7491 in 544.48s.\n",
      "Fold 5 (AUC): 0.74786 in 544.65s.\n",
      "\n",
      "Average AUC: 0.7491\n",
      "Training Time: 3289.0s\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ Wrapper\n",
    "noisy_logit_scores, noisy_logit_preds, noisy_logit_oof = train_noisy_model(logit_pipeline)\n",
    "\n",
    "submission['target'] = noisy_logit_preds\n",
    "submission.to_csv('../output/noisy_logit_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa63a4c",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "The wrapper function expects an estimator with a `predict_proba` method, so we hack together an equivalent using the softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742ed3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class extending Ridge Regression\n",
    "class ExtendedRidgeClassifier(RidgeClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        temp = self.decision_function(X)\n",
    "        return softmax(np.c_[-temp, temp])\n",
    "    \n",
    "# Ridge Regression\n",
    "ridge_pipeline = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    ExtendedRidgeClassifier(\n",
    "        alpha = 2.5553397058054763,\n",
    "        solver = 'saga',\n",
    "        random_state = RANDOM_SEED,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ef5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74906 in 8.92s.\n",
      "Fold 1 (AUC): 0.74859 in 8.25s.\n",
      "Fold 2 (AUC): 0.74975 in 9.75s.\n",
      "Fold 3 (AUC): 0.74979 in 9.84s.\n",
      "Fold 4 (AUC): 0.74914 in 8.71s.\n",
      "Fold 5 (AUC): 0.74758 in 9.27s.\n",
      "\n",
      "Average AUC: 0.74898\n",
      "Training Time: 54.74s\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression Baseline\n",
    "ridge_scores, ridge_preds, ridge_oof = train_model(ridge_pipeline)\n",
    "\n",
    "submission['target'] = ridge_preds\n",
    "submission.to_csv('../output/ridge_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e32835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74891 in 59.58s.\n",
      "Fold 1 (AUC): 0.74857 in 54.6s.\n",
      "Fold 2 (AUC): 0.74968 in 61.91s.\n",
      "Fold 3 (AUC): 0.74957 in 58.01s.\n",
      "Fold 4 (AUC): 0.7491 in 68.36s.\n",
      "Fold 5 (AUC): 0.74747 in 60.98s.\n",
      "\n",
      "Average AUC: 0.74888\n",
      "Training Time: 363.44s\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression w/ Wrapper\n",
    "noisy_ridge_scores, noisy_ridge_preds, noisy_ridge_oof = train_noisy_model(ridge_pipeline)\n",
    "\n",
    "submission['target'] = noisy_ridge_preds\n",
    "submission.to_csv('../output/noisy_ridge_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414dd5d",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "223fa37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "lda_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearDiscriminantAnalysis(\n",
    "        solver = 'eigen', \n",
    "        shrinkage = 0.17788226997464066\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70850e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74906 in 4.87s.\n",
      "Fold 1 (AUC): 0.74863 in 4.89s.\n",
      "Fold 2 (AUC): 0.74971 in 4.9s.\n",
      "Fold 3 (AUC): 0.74971 in 4.92s.\n",
      "Fold 4 (AUC): 0.74914 in 4.9s.\n",
      "Fold 5 (AUC): 0.74763 in 4.89s.\n",
      "\n",
      "Average AUC: 0.74898\n",
      "Training Time: 29.36s\n"
     ]
    }
   ],
   "source": [
    "lda_scores, lda_preds, lda_oof = train_model(lda_pipeline)\n",
    "\n",
    "submission['target'] = lda_preds\n",
    "submission.to_csv('../output/lda_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71eccd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74887 in 23.79s.\n",
      "Fold 1 (AUC): 0.74855 in 23.9s.\n",
      "Fold 2 (AUC): 0.74957 in 23.97s.\n",
      "Fold 3 (AUC): 0.74941 in 23.87s.\n",
      "Fold 4 (AUC): 0.74904 in 23.73s.\n",
      "Fold 5 (AUC): 0.74747 in 23.9s.\n",
      "\n",
      "Average AUC: 0.74882\n",
      "Training Time: 143.16s\n"
     ]
    }
   ],
   "source": [
    "noisy_lda_scores, noisy_lda_preds, noisy_lda_oof = train_noisy_model(lda_pipeline)\n",
    "\n",
    "submission['target'] = noisy_lda_preds\n",
    "submission.to_csv('../output/noisy_lda_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291acba",
   "metadata": {},
   "source": [
    "# SGDClassifier\n",
    "\n",
    "Again, since the wrapper function expects an estimator with a `predict_proba` method, we create an equivalent using softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec8aa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended SGDClassifier\n",
    "class ExtendedSGDClassifier(SGDClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        temp = self.decision_function(X)\n",
    "        return softmax(np.c_[-temp, temp])\n",
    "\n",
    "# SGDClassifier\n",
    "sgd_pipeline = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    ExtendedSGDClassifier(\n",
    "        learning_rate = 'adaptive', \n",
    "        penalty = 'l2', \n",
    "        alpha = 0.0064925580312465685, \n",
    "        eta0 = 0.00018074654973375143,\n",
    "        random_state = RANDOM_SEED\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819be5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74921 in 6.74s.\n",
      "Fold 1 (AUC): 0.74877 in 6.63s.\n",
      "Fold 2 (AUC): 0.74994 in 6.8s.\n",
      "Fold 3 (AUC): 0.74994 in 6.67s.\n",
      "Fold 4 (AUC): 0.74922 in 6.66s.\n",
      "Fold 5 (AUC): 0.74779 in 6.64s.\n",
      "\n",
      "Average AUC: 0.74914\n",
      "Training Time: 40.14s\n"
     ]
    }
   ],
   "source": [
    "sgd_scores, sgd_preds, sgd_oof = train_model(sgd_pipeline)\n",
    "\n",
    "submission['target'] = sgd_preds\n",
    "submission.to_csv('../output/sgd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a72c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74919 in 40.55s.\n",
      "Fold 1 (AUC): 0.74875 in 40.58s.\n",
      "Fold 2 (AUC): 0.74992 in 40.49s.\n",
      "Fold 3 (AUC): 0.74982 in 40.53s.\n",
      "Fold 4 (AUC): 0.74913 in 41.1s.\n",
      "Fold 5 (AUC): 0.74785 in 40.56s.\n",
      "\n",
      "Average AUC: 0.74911\n",
      "Training Time: 243.8s\n"
     ]
    }
   ],
   "source": [
    "noisy_sgd_scores, noisy_sgd_preds, noisy_sgd_oof = train_noisy_model(sgd_pipeline)\n",
    "\n",
    "submission['target'] = noisy_sgd_preds\n",
    "submission.to_csv('../output/noisy_sgd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576edfa",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7093e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "nb_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    MultinomialNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "464a7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.72464 in 2.03s.\n",
      "Fold 1 (AUC): 0.72559 in 2.01s.\n",
      "Fold 2 (AUC): 0.72667 in 1.98s.\n",
      "Fold 3 (AUC): 0.72574 in 2.04s.\n",
      "Fold 4 (AUC): 0.72654 in 2.0s.\n",
      "Fold 5 (AUC): 0.72384 in 2.04s.\n",
      "\n",
      "Average AUC: 0.7255\n",
      "Training Time: 12.1s\n"
     ]
    }
   ],
   "source": [
    "nb_scores, nb_preds, nb_oof = train_model(nb_pipeline)\n",
    "\n",
    "submission['target'] = nb_preds\n",
    "submission.to_csv('../output/nb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df467a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.72113 in 9.81s.\n",
      "Fold 1 (AUC): 0.72219 in 9.8s.\n",
      "Fold 2 (AUC): 0.72345 in 9.82s.\n",
      "Fold 3 (AUC): 0.72247 in 9.87s.\n",
      "Fold 4 (AUC): 0.72345 in 9.9s.\n",
      "Fold 5 (AUC): 0.72098 in 9.89s.\n",
      "\n",
      "Average AUC: 0.72228\n",
      "Training Time: 59.1s\n"
     ]
    }
   ],
   "source": [
    "noisy_nb_scores, noisy_nb_preds, noisy_nb_oof = train_noisy_model(nb_pipeline)\n",
    "\n",
    "submission['target'] = noisy_nb_preds\n",
    "submission.to_csv('../output/noisy_nb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a727af6",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340e121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron Classifier\n",
    "mlp_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        batch_size = 256, \n",
    "        early_stopping = True,\n",
    "        validation_fraction = 0.2,\n",
    "        n_iter_no_change = 5,\n",
    "        random_state = RANDOM_SEED\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa3a9438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.7526 in 28.65s.\n",
      "Fold 1 (AUC): 0.75186 in 22.55s.\n",
      "Fold 2 (AUC): 0.75366 in 30.8s.\n",
      "Fold 3 (AUC): 0.75401 in 28.9s.\n",
      "Fold 4 (AUC): 0.75352 in 26.8s.\n",
      "Fold 5 (AUC): 0.75279 in 26.77s.\n",
      "\n",
      "Average AUC: 0.75307\n",
      "Training Time: 164.48s\n"
     ]
    }
   ],
   "source": [
    "mlp_scores, mlp_preds, mlp_oof = train_model(mlp_pipeline)\n",
    "\n",
    "submission['target'] = mlp_preds\n",
    "submission.to_csv('../output/mlp_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c2e3f75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74878 in 124.57s.\n",
      "Fold 1 (AUC): 0.74928 in 139.05s.\n",
      "Fold 2 (AUC): 0.7496 in 125.93s.\n",
      "Fold 3 (AUC): 0.74939 in 124.82s.\n",
      "Fold 4 (AUC): 0.74871 in 121.33s.\n",
      "Fold 5 (AUC): 0.74677 in 129.83s.\n",
      "\n",
      "Average AUC: 0.74876\n",
      "Training Time: 765.52s\n"
     ]
    }
   ],
   "source": [
    "noisy_mlp_scores, noisy_mlp_preds, noisy_mlp_oof = train_noisy_model(mlp_pipeline)\n",
    "\n",
    "submission['target'] = noisy_mlp_preds\n",
    "submission.to_csv('../output/noisy_mlp_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80554d",
   "metadata": {},
   "source": [
    "# XGBoost with Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd704fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "xgb_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBClassifier(\n",
    "        booster = 'gblinear',\n",
    "        eval_metric = 'auc',\n",
    "        random_state = RANDOM_SEED,\n",
    "        alpha = 1.6282976774133507e-08, \n",
    "        **{'lambda': 0.008014767952226397}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f43b0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74914 in 9.28s.\n",
      "Fold 1 (AUC): 0.74864 in 9.13s.\n",
      "Fold 2 (AUC): 0.74983 in 9.11s.\n",
      "Fold 3 (AUC): 0.74987 in 9.17s.\n",
      "Fold 4 (AUC): 0.74918 in 9.13s.\n",
      "Fold 5 (AUC): 0.74769 in 9.19s.\n",
      "\n",
      "Average AUC: 0.74906\n",
      "Training Time: 55.02s\n"
     ]
    }
   ],
   "source": [
    "xgb_scores, xgb_preds, xgb_oof = train_model(xgb_pipeline)\n",
    "\n",
    "submission['target'] = xgb_preds\n",
    "submission.to_csv('../output/xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d875ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 (AUC): 0.74922 in 43.26s.\n",
      "Fold 1 (AUC): 0.74881 in 44.37s.\n",
      "Fold 2 (AUC): 0.74998 in 43.83s.\n",
      "Fold 3 (AUC): 0.74988 in 43.29s.\n",
      "Fold 4 (AUC): 0.74933 in 43.6s.\n",
      "Fold 5 (AUC): 0.74784 in 43.42s.\n",
      "\n",
      "Average AUC: 0.74918\n",
      "Training Time: 261.77s\n"
     ]
    }
   ],
   "source": [
    "noisy_xgb_scores, noisy_xgb_preds, noisy_xgb_oof = train_noisy_model(xgb_pipeline)\n",
    "\n",
    "submission['target'] = noisy_xgb_preds\n",
    "submission.to_csv('../output/noisy_xgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
